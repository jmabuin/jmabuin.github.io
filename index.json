[{"authors":["admin"],"categories":null,"content":"Thanks for your visit!\nMy name is José Manuel Abuín Mosquera (Rianxo, 1982). I am a software developer, computer engineer and researcher. Nowadays I work as Scientific Software Developer at Mestrelab Research S.L. and Bruker Daltonics SPR.\nMy main research interests are focused on the application of High Performance Computing and parallel programming to solve scientific problems, mainly in genomics and chemistry.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jmabuin.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Thanks for your visit!\nMy name is José Manuel Abuín Mosquera (Rianxo, 1982). I am a software developer, computer engineer and researcher. Nowadays I work as Scientific Software Developer at Mestrelab Research S.L. and Bruker Daltonics SPR.\nMy main research interests are focused on the application of High Performance Computing and parallel programming to solve scientific problems, mainly in genomics and chemistry.","tags":null,"title":"","type":"authors"},{"authors":["Robin Kobus","José M. Abuín","André Müller","Sören Lukas Hellmann","Juan C. Pichel","Tomás F. Pena","Andreas Hildebrandt","Thomas Hankeln","Bertil Schmidt"],"categories":null,"content":"","date":1583967600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583967600,"objectID":"5afb19fa4f18c0246d8dead870e9025d","permalink":"https://jmabuin.github.io/publication/20bmc/","publishdate":"2020-03-12T00:00:00+01:00","relpermalink":"/publication/20bmc/","section":"publication","summary":"Background: All-Food-Sequencing (AFS) is an untargeted metagenomic sequencing method that allows for the detection and quantification of food ingredients including animals, plants, and microbiota. While this approach avoids some of the shortcomings of targeted PCR-based methods, it requires the comparison of sequence reads to large collections of reference genomes. The steadily increasing amount of available reference genomes establishes the need for efficient big data approaches.Results: We introduce an alignment-free k-mer based method for detection and quantification of species composition in food and other complex biological matters. It is orders-of-magnitude faster than our previous alignment-based AFS pipeline. In comparison to the established tools CLARK, Kraken2, and Kraken2+Bracken it is superior in terms of false-positive rate and quantification accuracy. Furthermore, the usage of an efficient database partitioning scheme allows for the processing of massive collections of reference genomes with reduced memory requirements on a workstation (AFS-MetaCache) or on a Spark-based compute cluster (MetaCacheSpark).Conclusions: We present a fast yet accurate screening method for whole genome shotgun sequencing-based biosurveillance applications such as food testing. By relying on a big data approach it can scale efficiently towards large-scale collections of complex eukaryotic and bacterial reference genomes. AFS-MetaCache and MetaCacheSpark are suitable tools for broad-scale metagenomic screening applications. They are available at https://muellan.github.io/metacache/afs.html (C++ version for a workstation) and https://github.com/jmabuin/MetaCacheSpark (Spark version for big data clusters).","tags":["Big Data","Metagenomics","All Food Sequencing","AFS","HPC"],"title":"A Big Data Approach to Metagenomics for All-Food-Sequencing","type":"publication"},{"authors":["Cesar Piñeiro","José M. Abuín","Juan C. Pichel"],"categories":null,"content":"","date":1510268400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510268400,"objectID":"fd9c597c11f9d40f2a0b2d76648472a2","permalink":"https://jmabuin.github.io/publication/17bd/","publishdate":"2017-11-10T00:00:00+01:00","relpermalink":"/publication/17bd/","section":"publication","summary":"Perl is one of the most important programming languages in many research areas. However, the most relevant Big Data frameworks, Apache Hadoop, Apache Spark and Apache Storm, do not support natively this language. To take advantage of these Big Data engines Perl programmers should port their applications to Java or Scala, which requires a huge effort, or use utilities as Hadoop Streaming with the corresponding degradation in the performance. For this reason we introduce Perldoop2, a Big Data-oriented Perl-Java source-to-source compiler. The compiler is able to generate Java code from Perl applications for sequential execution, but also for running on clusters taking advantage of Hadoop, Spark and Storm engines. Perl programmers only need to tag the source code in order to use the compiler. Experimental results demonstrate the benefits of Perldoop2 in terms of ease of use, performance and scalability.","tags":["Big Data","Hadoop","NLP"],"title":"Perldoop2: a Big Data-oriented source-to-source Perl-Java compiler","type":"publication"},{"authors":["José M. Abuín","Tomás F. Pena","Juan C. Pichel"],"categories":null,"content":"","date":1496613600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496613600,"objectID":"a64b311ae43eec11e151c4b203bb6e6d","permalink":"https://jmabuin.github.io/publication/17bio/","publishdate":"2017-06-05T00:00:00+02:00","relpermalink":"/publication/17bio/","section":"publication","summary":"Motivation: One basic step in many bioinformatics analyses is the Multiple Sequence Alignment (MSA). One of the state of the art tools to perform MSA is PASTA (Practical Alignments using SATé and TrAnsitivity). PASTA supports multithreading but it is limited to process datasets on shared memory systems. In this work we introduce PASTASpark, a tool that uses the Big Data engine Apache Spark to boost the performance of the alignment phase of PASTA, which is the most expensive task in terms of time consumption. Results: Speedups up to 10× with respect to single-threaded PASTA were observed, which allows to process an ultra-large dataset of 200,000 sequences within the 24-hr limit.Availability: PASTASpark is an Open Source tool available at https://github.com/citiususc/pastaspark","tags":["Big Data","Genomics","MSA","PASTA","HPC"],"title":"PASTASpark: multiple sequence alignment meets Big Data","type":"publication"},{"authors":["José M. Abuín","Juan C. Pichel","Tomás F. Pena","Jorge Amigo"],"categories":null,"content":"","date":1463349600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463349600,"objectID":"adbcc3866fbae7cb761949b20ad48515","permalink":"https://jmabuin.github.io/publication/16plo/","publishdate":"2016-05-16T00:00:00+02:00","relpermalink":"/publication/16plo/","section":"publication","summary":"Next-generation sequencing (NGS) technologies have led to a huge amount of genomic data that need to be analyzed and interpreted. This fact has a huge impact on the DNA sequence alignment process, which nowadays requires the mapping of billions of small DNA sequences onto a reference genome. In this way, sequence alignment remains the most time-consuming stage in the sequence analysis workflow. To deal with this issue, state of the art aligners take advantage of parallelization strategies. However, the existent solutions show limited scalability and have a complex implementation. In this work we introduce SparkBWA, a new tool that exploits the capabilities of a big data technology as Spark to boost the performance of one of the most widely adopted aligner, the Burrows-Wheeler Aligner (BWA). The design of SparkBWA uses two independent software layers in such a way that no modifications to the original BWA source code are required, which assures its compatibility with any BWA version (future or legacy). SparkBWA is evaluated in different scenarios showing noticeable results in terms of performance and scalability. A comparison to other parallel BWA-based aligners validates the benefits of our approach. Finally, an intuitive and flexible API is provided to NGS professionals in order to facilitate the acceptance and adoption of the new tool. The source code of the software described in this paper is publicly available at https://github.com/citiususc/SparkBWA, with a GPL3 license.","tags":["Big Data","Genomics","Spark","BWA","Alignment","HPC"],"title":"SparkBWA: Speeding Up the Alignment of High-Throughput DNA Sequencing Data","type":"publication"},{"authors":["José M. Abuín","Juan C. Pichel","Tomás F. Pena","Jorge Amigo"],"categories":null,"content":"","date":1440885600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1440885600,"objectID":"980193c4377288450283680380d50c72","permalink":"https://jmabuin.github.io/publication/15bio/","publishdate":"2015-08-30T00:00:00+02:00","relpermalink":"/publication/15bio/","section":"publication","summary":"BigBWA is a new tool that uses the Big Data technology Hadoop to boost the performance of the Burrows-Wheeler Aligner (BWA). Important reductions in the execution times were observed when using this tool. In addition, BigBWA is fault tolerant and it does not require any modification of the original BWA source code.","tags":["Big Data","Genomics","BWA","Alignment","HPC"],"title":"BigBWA: Approaching the Burrows-Wheeler Aligner to Big Data Technologies","type":"publication"},{"authors":["José M. Abuín","Juan C. Pichel","Tomás F. Pena","Pablo Gamallo","Marcos García"],"categories":null,"content":"","date":1414796400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1414796400,"objectID":"aa0c1e1d2e24baec878d996c7547c4cb","permalink":"https://jmabuin.github.io/publication/14bd/","publishdate":"2014-11-01T00:00:00+01:00","relpermalink":"/publication/14bd/","section":"publication","summary":"Hadoop is one of the most important implemen- tations of the MapReduce programming model. It is written in Java and most of the programs that run on Hadoop are also written in this language. Hadoop also provides an utility to execute applications written in other languages, known as Hadoop Streaming. However, the ease of use provided by Hadoop Streaming comes at the expense of a noticeable degradation in the performance.In this work, we introduce Perldoop, a new tool that au- tomatically translates Hadoop-ready Perl scripts into its Java counterparts, which can be directly executed on Hadoop while improving their performance significantly. We have tested our tool using several Natural Language Processing (NLP) modules, which consist of hundreds of regular expressions, but Perldoop could be used with any Perl code ready to be executed with Hadoop Streaming. Performance results show that Java codes generated using Perldoop execute up to 12x faster than the original Perl modules using Hadoop Streaming. In this way, the new NLP modules are able to process the whole Wikipedia in less than 2 hours using a Hadoop cluster with 64 nodes.","tags":["Big Data","Hadoop","NLP"],"title":"Perldoop: Efficient Execution of Perl Scripts on Hadoop Clusters","type":"publication"}]